{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "286b2f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first done\n"
     ]
    }
   ],
   "source": [
    "from scrapper.pinksalelaunchpad import scrape_pinksale\n",
    "\n",
    "headings, tokens_data = scrape_pinksale()\n",
    "headings.append('Category')\n",
    "headings.append('start time')\n",
    "headings.append('end time')\n",
    "\n",
    "print('first done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3a597472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "def extract_time_and_category(title, table1, table2):\n",
    "    start_time = ''\n",
    "    end_time = ''\n",
    "    category = ''\n",
    "    soup = BeautifulSoup(table1)\n",
    "    table_rows = soup.find_all('tr')\n",
    "    for row in table_rows:\n",
    "        row_data = row.find_all('td')\n",
    "        if(len(row_data)<2):\n",
    "            continue\n",
    "        if('Start Time' in row_data[0].text):\n",
    "            start_time = row_data[1].text\n",
    "        if('End Time' in row_data[0].text):\n",
    "            end_time = row_data[1].text\n",
    "    if('Fair Launch' in title):\n",
    "        category = 'Fair Launch'\n",
    "    elif('Subscription' in title):\n",
    "        category = 'Subscription'\n",
    "    else:\n",
    "        soup = BeautifulSoup(table2)\n",
    "        table_rows = soup.find_all('tr')\n",
    "        for row in table_rows:\n",
    "            row_data = row.find_all('td')\n",
    "            if(len(row_data)<2):\n",
    "                continue\n",
    "            if('Whitelist' in row_data[1].text):\n",
    "                category = 'Whitelist'\n",
    "            if('Public' in row_data[1].text):\n",
    "                category = 'Public Presale'\n",
    "    return start_time, end_time, category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c4fa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link fetching -> wait for loading the page\n",
      "Yutu Fair Launch\n",
      "done this link\n",
      "link fetching -> wait for loading the page\n",
      "KISEKI Fair Launch\n",
      "done this link\n",
      "link fetching -> wait for loading the page\n",
      "Lynx Presale\n",
      "done this link\n",
      "link fetching -> wait for loading the page\n",
      "SHIBAS Token Fair Launch\n",
      "done this link\n",
      "link fetching -> wait for loading the page\n",
      "GPT Presale\n",
      "done this link\n",
      "link fetching -> wait for loading the page\n",
      "XTF AI Presale\n",
      "done this link\n",
      "link fetching -> wait for loading the page\n",
      "TuNian Presale\n",
      "done this link\n",
      "link fetching -> wait for loading the page\n",
      "2023 APE Presale\n",
      "done this link\n",
      "link fetching -> wait for loading the page\n",
      "GreenLeage Presale\n",
      "done this link\n",
      "link fetching -> wait for loading the page\n",
      "MoonRabbit Fair Launch\n",
      "done this link\n",
      "link fetching -> wait for loading the page\n",
      "TSWSToken Presale\n",
      "done this link\n",
      "link fetching -> wait for loading the page\n",
      "BANANA BANANA Fair Launch\n",
      "done this link\n",
      "link fetching -> wait for loading the page\n",
      "Rabbit 23 Presale\n",
      "done this link\n",
      "link fetching -> wait for loading the page\n",
      "FomoBSC Presale\n",
      "done this link\n",
      "link fetching -> wait for loading the page\n",
      "Pi King Presale\n",
      "done this link\n",
      "link fetching -> wait for loading the page\n"
     ]
    }
   ],
   "source": [
    "# for individual pages\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "from scrapper.pinksalelaunchpad import create_driver\n",
    "\n",
    "def scrapeTimeAndCategory(tokens_data):\n",
    "    profile_links = tokens_data['profile_link']\n",
    "    time_period = 10\n",
    "    start_time_data = []\n",
    "    end_time_data = []\n",
    "    category_data = []\n",
    "    for link in profile_links:\n",
    "        browser = create_driver(show_browser=False)\n",
    "        browser.get(link)  \n",
    "        print('link fetching -> wait for loading the page')\n",
    "        time.sleep(time_period)\n",
    "        title =  browser.find_elements(By.CLASS_NAME, \"title\")[0].text\n",
    "        print(title)\n",
    "\n",
    "        # for start time\n",
    "        tables = browser.find_elements(By.CLASS_NAME, \"table-container\")\n",
    "        table1 = tables[0].get_attribute('innerHTML')\n",
    "        table2 = tables[1].get_attribute('innerHTML')\n",
    "        browser.quit()\n",
    "        start_time, end_time, category = extract_time_and_category(title, table1, table2)\n",
    "        start_time_data.append(start_time)\n",
    "        end_time_data.append(end_time)\n",
    "        category_data.append(category)\n",
    "        print('done this link')\n",
    "    return start_time_data, end_time_data, category_data\n",
    "\n",
    "start_time, end_time, category = scrapeTimeAndCategory(tokens_data)\n",
    "print(start_time)\n",
    "print(end_time)\n",
    "print(category)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a3c3761b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-20 21:38:01.627248+00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.date(2023, 1, 20)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timezone\n",
    "utctime = datetime.now(timezone.utc)\n",
    "print(utctime)\n",
    "utctime.date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1f877cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 1, 20, 0, 0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datestring = '2023.01.20'\n",
    "datetime.strptime(datestring, '%Y.%m.%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499ff62e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
